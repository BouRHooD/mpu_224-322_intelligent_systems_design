# –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –±–∞–∑–µ –ù–° –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è Leonov Vladislav 181-311
# –§–ò–û –∞–≤—Ç–æ—Ä–∞: –õ–µ–æ–Ω–æ–≤ –í–ª–∞–¥–∏—Å–ª–∞–≤ –î–µ–Ω–∏—Å–æ–≤–∏—á
# E-mail –∞–≤—Ç–æ—Ä–∞: bourhood@gmail.com
# –ì—Ä—É–ø–ø–∞: 224-322
# –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç: –ú–æ—Å–∫–æ–≤—Å–∫–∏–π –ü–æ–ª–∏—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç
# –ì–æ–¥ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏: 11.05.2023
# –£—á–µ–±–Ω—ã–π –∫—É—Ä—Å: https://online.mospolytech.ru/course/view.php?id=10055
########################################################################################################################

import numpy as np
import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

'''–§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏''' # Softmax
class Sigmoid:
    output = []
    def activate_neurons(self, input):
        self.output = 1 / (1 + np.exp(-input))
        return self.output

    def backward(self, error):
        # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Å–∏–≥–º–æ–∏–¥—ã * error
        return self.output * (1 - self.output) * error

class ReLu:
    '''ReLu - Rectified Linear Unit (–í—ã–ø—Ä—è–º–ª–µ–Ω–Ω—ã–µ –ª–∏–Ω–µ–π–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã)'''
    input = []
    output = []
    def activate_neurons(self, input_sum_neurons):
        self.input = input_sum_neurons
        return np.maximum(0, input_sum_neurons)

    def backward(self, error):
        # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –æ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        error[self.input < 0] = 0
        return error

'''–ö–ª–∞—Å—Å —Å–ª–æ—è'''
class LayerPerceptron:
    '''–ö–ª–∞—Å—Å —Å–ª–æ—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞'''
    def __init__(self, input_size, output_size, input_name_layer, in_func_activation):
        self.input = []                                 # –í—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–ª–æ–π —Å–µ—Ç–∏
        self.output = []                                # –í—ã—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–ª–æ—è —Å–µ—Ç–∏

        self.used_func_activation = in_func_activation  # –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        self.name_layer = input_name_layer              # –ù–∞–∑–≤–∞–Ω–∏–µ —Å–ª–æ—è
        self.generate_weight(input_size, output_size)   # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —Å–ª–æ—è

    def generate_weight(self, input_size, output_size):
        self.Weights = np.random.uniform(-0.15, 0.15, size=(input_size, output_size))
        self.bias = np.random.uniform(-0.15, 0.15, size=output_size)
    
    '''–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤'''
    def out_neurons(self, input):
        '''–í—ã—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–æ–≤ (–≤–µ–∫—Ç–æ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)'''
        self.input = input
        # –ü–µ—Ä–µ–º–Ω–æ–∂–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è –Ω–∞ –º–∞—Ç—Ä–∏—Ü—É –≤–µ—Å–æ–≤ (‚àëweight*x) (dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])) + bias
        self.output = np.dot(input, self.Weights) + self.bias
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        self.output = self.used_func_activation.activate_neurons(self.output)
        return self.output
    
    def create_csv(self, count):
        import os
        folder_ui_path = '_out' if os.path.isdir('_out') is True else 'L3/_out'
        np.savetxt(f"{folder_ui_path}/{self.name_layer}_weights_{count}.csv", self.Weights, delimiter=",")
    
'''–ö–ª–∞—Å—Å –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞'''
class Perceptron:
    '''–ö–ª–∞—Å—Å –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞'''
    def __init__(self):
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞ (input_layer(784)->hidden(50)->l2_output(10))
        self.l1_hidden = LayerPerceptron(784, 50, 'l1_hidden', ReLu())
        self.l2_output = LayerPerceptron(50, 10, 'l2_output', Sigmoid())
        
    def create_csv_weights_perceptron(self, count):
        self.l1_hidden.create_csv(count=count)
        self.l2_output.create_csv(count=count)

    '''–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤'''
    def out_perceptron(self, input):
        input = input.reshape((1, -1))
        output = self.l1_hidden.out_neurons(input)    # func_activate(sum(X*Weights) + bias)
        output = self.l2_output.out_neurons(output)   # func_activate(sum(X*Weights) + bias) 
        return output

    '''–û–±—É—á–µ–Ω–∏–µ'''
    def train(self, in_train_images, in_train_labels, in_count_use_img=1000, in_epochs=1, in_learning_rate=0.001, ui_progress_bar=None, window=None):
        '''–û–±—É—á–µ–Ω–∏–µ'''
        self.count_train_imgages = len(in_train_images[:in_count_use_img])    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ –∫–æ–ª-–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –≤–µ—Å–∞ –¥–æ –æ–±—É—á–µ–Ω–∏—è
        if window is not None: window.weights_history.append([self.l1_hidden.Weights, self.l2_output.Weights]); 

        # –ü—Ä–æ—Ö–æ–¥–∏–º—Å—è –ø–æ —ç–ø–æ—Ö–∞–º –æ–±—É—á–µ–Ω–∏—è
        for epoch in range(in_epochs):
            # ProgressBar 
            if ui_progress_bar is not None: ui_progress_bar.setValue(0); 
            if ui_progress_bar is not None: ui_progress_bar.setMinimum(0); 
            if ui_progress_bar is not None: ui_progress_bar.setMaximum(self.count_train_imgages); 

            # Train
            for i in range(self.count_train_imgages):
                source_image = in_train_images[i]                           # –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 28—Ö28
                source_label = in_train_labels[i]                           # –†–∞–∑–º–µ—Ç–∫–∞ –≤ —É–Ω–∏—Ç–∞—Ä–Ω–æ–º –∫–æ–¥–µ (ùê≤_ùê¢)
                y_true = np.argmax(source_label)                            # –û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç —Å–µ—Ç–∏
                
                input_layer = source_image.flatten()                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –ø–∏–∫—Å–µ–ª–∏ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É 28—Ö28=784 (ùê±_ùê¢)
                y_pred = self.out_perceptron(input_layer)                   # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –≤—Å–µ —Å–ª–æ–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤ (–≤–µ–∫—Ç–æ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π) (ùê≤_pred_i)
                y_result = np.argmax(y_pred)                                # –û—Ç–≤–µ—Ç –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞ (–º–∞–∫—Å. –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)

                ### **–ê–ª–≥–æ—Ä–∏—Ç–º –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏ (–∞–Ω–≥–ª. backpropagation)**
                ## https://machinelearningmastery.ru/implement-backpropagation-algorithm-scratch-python/
                ## https://habr.com/ru/articles/271563/
                ## –í—ã—á–∏—Å–ª—è–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Å–ª–æ–µ–≤ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞
                ## –°—Ç–æ—Ö–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫
                error_2 = y_pred - source_label                                         # –í—ã—á–∏—Å–ª—è–µ–º –æ—à–∏–±–∫—É (–≤–µ–∫—Ç–æ—Ä –æ—à–∏–±–æ–∫) (ùêûrror_i = ùê≤_ùê¢ ‚àí ùê≤_pred_i)
                error_2_delta = self.l2_output.used_func_activation.backward(error_2)   # –î–µ–ª—å—Ç–∞ –æ—à–∏–±–∫–∏
                # –î–µ–ª—å—Ç–∞ –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–º —Å–ª–æ–∏ 1 
                error_1 = np.dot(error_2_delta, self.l2_output.Weights.T)               # –ü–µ—Ä–µ–¥–∞–µ–º –æ—à–∏–±–∫—É –Ω–∞ –Ω–∏–∂–Ω–∏–π —Å–ª–æ–π
                error_1_delta = self.l1_hidden.used_func_activation.backward(error_1)   # –î–µ–ª—å—Ç–∞ –æ—à–∏–±–∫–∏

                # –ú–µ–Ω—è–µ–º –≤–µ—Å–∞ –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –æ—à–∏–±–∫–∞–º
                self.l1_hidden.Weights -= error_1_delta*self.l1_hidden.input.T*in_learning_rate
                self.l2_output.Weights -= error_2_delta*self.l2_output.input.T*in_learning_rate

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ ProgressBar
                if ui_progress_bar is not None: ui_progress_bar.setValue(i); 
                if window is not None: window.SystemMassage_TextBrowser_append(f"[{epoch+1}/{in_epochs} —ç–ø–æ—Ö–∞] –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ {i + 1}/{self.count_train_imgages}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç {y_result}, –æ–∂–∏–¥–∞–ª–æ—Å—å {y_true}"); 
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ
            if window is not None: window.weights_history.append([self.l1_hidden.Weights, self.l2_output.Weights]); 
            self.create_csv_weights_perceptron(count=epoch)
        
        # –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º 0% –≤ ProgressBar
        if ui_progress_bar is not None: ui_progress_bar.setValue(0); 

    '''–†–∞—Å–ø–æ–∑–Ω–æ–≤–∞–Ω–∏–µ'''
    def recognition(self, image):
        '''–†–∞—Å–ø–æ–∑–Ω–æ–≤–∞–Ω–∏–µ'''
        x = image.flatten()                               # –í—ã—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–∏–∫—Å–µ–ª–∏ –≤ –æ–¥–∏–Ω —Ä—è–¥ 28—Ö28=784
        y_pred = self.out_perceptron(x)                   # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –≤—Å–µ —Å–ª–æ–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤ (–≤–µ–∫—Ç–æ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π) (ùê≤_pred_i)
        return np.argmax(y_pred)                          # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–º–∞–∫—Å. –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
    
'''–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è'''
def stat(perceptron_:Perceptron, in_test_images, in_test_labels):
    '''–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è - –°—Ç—Ä–æ–∏–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫'''
    def confusion_matrix(y_pred, y_true):
        classes = np.unique(y_true)
        classes.sort()
        conf_m = np.zeros(shape=(len(classes), len(classes)))
        for i in classes:
            for j in classes:
                conf_m[i, j] = np.logical_and((y_pred==i), (y_true==j)).sum()
        return conf_m, classes
    
    def accuracy(y_pred, y_true):
        y_pred = np.array(y_pred)
        y_true = np.array(y_true)
        return (y_pred==y_true).sum()/y_true.size
    
    y_true = []
    y_pred = []
    for x, y in zip(in_test_images, in_test_labels):
        y_true.append(np.argmax(y))
        y_pred.append(perceptron_.recognition(x)) 
        
    confusion_matrix = confusion_matrix(y_pred,y_true)
    perceptron_accuracy = round(accuracy(y_pred, y_true)*100,5)
    print(f"Accuracy perceptron: {perceptron_accuracy}%")
    df_cm = pd.DataFrame(confusion_matrix[0], range(10), range(10))

    sn.set(font_scale=1.4) # for label size
    sn.heatmap(df_cm, annot=True, annot_kws={"size": 8},fmt='g',cmap="Blues") # font size
    plt.show()
    return f"Accuracy perceptron: {perceptron_accuracy}%"

'''–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤–µ—Å–∞'''
def view_weigts(in_weights):
    weights_T = in_weights.T
    f, ax = plt.subplots(2, 5, figsize=(12,5), gridspec_kw={'wspace':0.05, 'hspace':0.2}, squeeze=True)    
    for index, img in enumerate(weights_T):
        index_cell = index % 5
        index_row = 0 if index < 5 else 1
        ax[index_row, index_cell].axis("off")
        if img.shape[0] == 784: ax[index_row, index_cell].imshow(img.reshape((28,28)), cmap='gray'); 
        else: ax[index_row, index_cell].imshow(img.reshape((5,10)), cmap='gray'); 
        ax[index_row, index_cell].set_title(str(index))
    plt.show()